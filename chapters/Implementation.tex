\chapter{Implementation}

The actual implementation may need to diverge from the abstract
defintion of the algorithm for practicality, simplicity or
performance reasons.

Many of the operations can be optimized for some particular
subset of datasets and features.

In this part we will use actual code from the program to show 
the implementation. For an introduction to the language 
Go that has been used see the appendix.

\section{Algorithm}

The algorithm was implemented as:

\begin{verbatim}
type Setup struct {
	Db  *Database
	Out Pooler
	In  Pooler

	Extender Extender

	Extendable  Filter
	Outputtable Filter

	PostProcess PostProcess
}

func Run(s *Setup) {
	prepareSpexs(s)
	for {
		p, valid := s.In.Take()
		if !valid {
			return
		}

		extensions := s.Extender(p)
		for _, extended := range extensions {
			if s.Extendable(extended) {
				s.In.Put(extended)
			}
			if s.Outputtable(extended) {
				s.Out.Put(extended)
			}
		}

		if s.PostProcess(p) != nil {
			break
		}
	}
}
\end{verbatim}

Setup is a structure designed to hold the full setup of the algorithm.
The algorithm is very similar to the algorithm described in the theoretical
part, with the slight addition of PostProcess.

\section{Architecture}

The main criteria for designing program have been described in D. Parnas
paper On the Decomposition of Programs. It suggests decomposing into
isolated units and parts that are likely to change together.

We chose the following decomposition:

\begin{verbatim}
	Configuration
	Dataset reader
	Setup
	Algorithm
		Sets
		Pools
		Extenders
		Features
		Filters
	Printer
\end{verbatim}

\subsection{Configuration}

One problem with flexible algorithms is that they a lot of ways to be run.
This often would need having tens or hundereds of program flags.
To avoid this problem we decided to use a json file for the program
configuration.

Example Configuration.

The problem with only using a json file is that when running from
command line it may be more comfortable using flags. To solve this problem
we added replacement strings into the json files that can be given in as
a program argument.

\begin{verbatim}
	"Datasets" : {
		"fore" : { "File" : "$input$"
	...
\end{verbatim}

When using spexs2 --conf conf.json input=filename the input will be
replaced by filename. Also there is optional default value if
one wasn't given.

\subsection{Dataset reader}

One of the most likely things to change is the input format. As an 
example we can have different delimiters. By adding this separation
immediately we can avoid the future problem of trying to support multiple
formats.

\subsection{Datasets}

We also may need to process several files. This means that we should
treat each file as a separate entity and allow calculate features
only on part of the dataset.

\subsection{Setup}

There are a lot of ways to setup the program. This allows us to separate
the initialization all of the structures necessary for the algorithm
from the algorithm itself.

\subsection{Algorithm}

This is an obvious separation. This is the main driver of the algorithm
and shouldn't know anything about the rest of the setup. Also there
are two versions of the algorithms one parallel the other not.

\subsection{Sets}

Since we need a collection how to store the matching positions it suggests
the need for a set datatype.

\subsection{Pools}

There can be different performance characteristics when using a particular
implementation. Most importantly to support parallelism they should
be ideally lock-free, but we can use locked version as well.

For the pools we have several choices: lifo, fifo or priority.

If we use a fifo queue as the in pool the algorithm does a breadth first
search of patterns. This can be problematic since we would need a lot of
memory to hold all the patterns in memory.

A lifo queue for in pool is a more reasonable choice for memory problems since we need
to hold less patterns in memory.

A priority queue suits for the out pool since we can easily then
use some feature to sort the queue and choose only a limited amount.

\subsection{Extenders}

As we saw in the theoretical part there are a lot of ways to extend
the query. Hence it is reasonable to decompose into a separate piece from
the algorithm.

\subsection{Features}

We can use these features to find out something about the query.
They each feature is defined as:

\begin{verbatim}
type Feature func(q *Query) (float64, string)
\end{verbatim}

Most of features are in $\Real$, but for some there
is some extended information that we may wish to know - hence
the need for additional string value. One of the simplest
is Pattern representation.

Also many of the features are defined in terms of multiple datasets.
We can use a closure to easily define a more generic feature.

Example:

\begin{verbatim}
func Matches(dataset []int) Feature {
	return func(q *Query) (float64, string) {
		matches := countf(q.Pos, dataset)
		return matches, ""
	}
}
\end{verbatim}

Here the Matches function creates a feature function defined
for dataset.

We can use the name in the configuration file as "Matches(fore)".

\subsection{Filters}

If a feature returns a floating point value we can easily turn that
into a filter by specifying a minimum or/and maximum value.

For example to give a lower and higher limits to some feature:

\begin{verbatim}
func featureFilter(feature Feature, min float64, max float64) Filter {
	return func(q *Query) bool {
		v, _ := feature(q)
		return (min <= v) && (v <= max)
	}
}
\end{verbatim}

Of course there are some filters that cannot be defined by features hence
there is still possibility to make separate filters. Such as disallowing
star symbol in the beginning of the pattern.

\subsection{Printer}

Although we use a general formatting there may be a need to save into
several files or output some extended information of the query.

\section{Debugging}

Debugging is a important part of development process hence the need for
more information how the algorithm is working.

Often this is resolved by adding some debug statments:

\begin{verbatim}
	for i := 0; i < 100; i += 1{
		printf("picking")
		a := pick()
		printf("picked %v", a)

		printf("picking")
		b := pick()
		printf("picked %v", b)
		
		out.put(a + b)
	}
\end{verbatim}

This can be harmful to the readability of the code. To fix this debugging 
problem we use closures.

\begin{verbatim}
	type PickFunc func() Thing
	func debuggable(fn PickFunc) PickFunc {
		return func() Thing {
			printf("start")
			p := fn()
			printf("picked %v" p)
			return p
		}
	}

	pick = debuggable(pick)
	for i := 0; i < 100; i += 1{
		a := pick()
		b := pick()
		out.put(a + b)
	}
\end{verbatim}

As we can see the algorithm implementation is much more readable.

