\chapter{Implementation}

Here we discuss a practical implementation, \emph{spexs2}, for
pattern discovery in sequences. 

In this chapter we will discuss a practical implementation, \emph{spexs2}, for pattern discovery in sequences. We only discuss parts that we consider non-trivial or interesting and could be useful in implementing other algorithms.

Information about the full source code is in the Appendix B and C.

\section{Architecture}

The main criteria for designing program have been described in D. Parnas
paper "On the Criteria To Be Used in Decomposing Systems into Modules"\cite{Parnas72}. It suggests decomposing into isolated units and parts that are likely to change together.

We chose the following module decomposition for the application:

\begin{small}
\begin{description}
    \itemsep-0.5em
    \item[Configuration] structure for holding the configuration data
    \item[Setup] based on the configuration initializes data-structures and functions for the algorithm
    \item[Reader] reads in the data from files
    \item[Database] a collection of datasets
    \item[Algorithm] the SPEXS2 algorithm
    \item[Printer] prints the result queries
\end{description}
\end{small}

The program starts by interpreting flags, then it marshals configuration file onto an internal structure, this configuration is given into setup module. Setup module initializes (as defined by configuration) a reader, a printer and also prepares structures for algorithm. Then the reader reads input to the database. Then the algorithm is activated and finally it is printed out with Printer.

This structure is universal for algorithm implementations and allows easily to add more configuration options, different input formats and different output formats. By changing the configuration, reader and printer we could make it a web service instead of running it on a command line.

\section{Configuration}

One problem with flexible algorithms is that there are a lot of ways to be run. This can lead to having tens or hundereds of command-line flags for the application.

To avoid this problem we first decided to use a \emph{json} file for the program configuration. Using \emph{json} requires exact placement of commas and quotes that caused a lot of problems, hence we started using \emph{yaml} that is more suitable for human input.

\tow{Short example of a configuration file.}

When running the program from command line it can be uncomfortable to make little changes to the configuration files. In these cases a command line flag would be much easier. To solve this problem we added markup into the json files so they could be replaced with a flag.

For example, inside the configuration file:

\begin{verbatim}
    "Datasets" : {
        "fore" : { "File" : "$input:main$"
        ...
\end{verbatim}

Using \emph{spexs2 --conf conf.json input=other} would replace the "File" value with "other". If there is no flag from command line is given, it will be replaced with "main".

The configuration file can be problematic for running the first time. You first need to find a configuration file for your application. To remedy this problem the application could provide sample configuration files that can be used directly from the command line.

\section{Input and Output}

\tow{about importance of separating the input reader and output printer from the algorithmic code}

\section{Alphabet and Database}

\tow{about problems with large alphabets and datasets}

\section{Pools}

There can be different performance characteristics when using a particular implementation. Most importantly to support parallelism they should be ideally lock-free, but we can use locked version as well.

\todo[inline]{remove the lock-free stuff}

If we use a fifo queue as the in pool the algorithm does a breadth first search of patterns. This can be problematic since we would need a lot of memory to hold all the patterns in memory.

A lifo queue for in pool is a more reasonable choice for memory problems since we need to hold less patterns in memory.

A priority queue suits for the output pool since we can easily then use some feature to sort the queue. A lock-free priority queue would be preferred, but it can be hard to get right. \todo{link to lock-free queues}

Trivial solution would be to use locks for enqueuing and dequeuing, but under high contention it will become a bottleneck.

We know that most of the time we do not need all the results, but only the best. We also know that the result limit is usually several magnitudes smaller than the number of output candidates; this means most of the queries put into the result queue will be immediately discarded.

Uf the query is worse than the worst in the priority queue, it can be discarded immediately without doing push/pop. If we allow for that check to fail once in a while - we can make it mostly lock-free.

\section{Features and Filters}

\tow{simpler and examples}

One problem is that the amount of possible filters it's useful to construct them from some other features. Or if we wish to use multiple filters we can combine them.

We can use these features to find out something about the query. They each feature is defined as:

\begin{verbatim}
type Feature func(q *Query) (float64, string)
\end{verbatim}

Most of features are in $\Re$, but for some there is some extended information that we may wish to know - hence the need for additional string value. One of the simplest is Pattern representation.

Also many of the features are defined in terms of multiple datasets. We can use a closure to easily define a more generic feature.

Example:

\begin{verbatim}
func Matches(dataset []int) Feature {
    return func(q *Query) (float64, string) {
        matches := countf(q.Pos, dataset)
        return matches, ""
    }
}
\end{verbatim}

Here the Matches function creates a feature function defined for dataset.

We can use the name in the configuration file as "Matches(fore)".

If a feature returns a floating point value we can easily turn that into a filter by specifying a minimum or/and maximum value.

For example to give a lower and higher limits to some feature:

\begin{verbatim}
func featureFilter(feature Feature, min float64, max float64) Filter {
    return func(q *Query) bool {
        v, _ := feature(q)
        return (min <= v) && (v <= max)
    }
}
\end{verbatim}

Of course there are some filters that cannot be defined by features hence there is still possibility to make separate filters. Such as disallowing star symbol in the beginning of the pattern.

\section{Synchronized Tree Traversal}

\emph{spexs2} can be seen as a pattern tree traversal algorithm with some extra logic. Implementing search over a tree requires synchronization such that there are only a certain number of workers and that they wouldn't die of starvation.

Without synchronization the parallel version looks like:

\begin{algorithm}[H]
    \caption{Tree traversal}
\begin{algorithmic}[1]
    \Ensure{All nodes in tree get processed with fn}

    \Function{visit}{tree, start, fn, examine?}
        \Let{$unvisited$}{\{ start \})}
        
        \Spawn
            \While{$unvisited$ not empty}
                \Let{$node$}{$unvisited$.take()}
                \State fn($node$)
                \For{ $child \in$ children($node$) }
                    \If{ examine?($child$) }
                        \State $unvisited$.put($child$)
                    \EndIf
                \EndFor
            \EndWhile
        \EndSpawn

        \State{wait for workers}
    \EndFunction
\end{algorithmic}
\end{algorithm}

This would not work correctly with multiple workers since there are race conditions and the workers can die early due to starvation.

The solution is to control worker startup and only terminate workers if all have finished and there are no more items in unvisited set.

\begin{algorithm}[H]
    \caption{Synchronized graph traversal}
\begin{algorithmic}[1]
    \Ensure{All nodes in $graph$ get processed with $fn$}

    \Function{Visit}{graph, start, fn, examine?}
        \Let{added}     {new semaphore(0)}
        \Let{$terminate$} {false}
        \Let{mutex}     {new mutex()}
        \Let{$workers$}   {0}
        \Let{$unvisited$} {\{ start \}}
        \State $added$.signal()
        
        \Spawn
            \While{$true$}
                \State added.wait()
                \State mutex.lock()
                \If{ $terminate$ }
                    \State added.signal()
                    \State mutex.unlock()
                    \State{\textbf{break}}
                \EndIf

                \Let{$node$}{$unvisited$.take()}
                \Let{$workers$}{$workers$ + 1}
                \State mutex.unlock()
                \Statex
                \State fn($node$)
                \Statex
                \For{ $child \in$ children($node$) }
                    \State mutex.lock()
                    \If{ examine?($child$) }
                        \State $unvisited$.put($child$)
                        \State added.signal()
                    \EndIf
                    \State mutex.unlock()
                \EndFor
                \Statex
                \State mutex.lock()
                \Let{$workers$}{$workers - 1$}
                \If{$workers = 0$ and $unvisited = \{\}$}
                    \Let{$terminate$}{true}
                    \State added.signal()
                \EndIf
                \State mutex.unlock()
            \EndWhile
        \EndSpawn

        \State{wait for workers}
    \EndFunction
\end{algorithmic}
\end{algorithm}

We use $mutex$ to protect variables and data structures. Semaphore $added$ tracks how many items are in the $unvisited$ set, if the process finally terminates it is turned into a turnstile on line 31 and 13. Variable $workers$ tracks how many workers are busy.

\section{Debugging}

Seeing how the algorithm works is very useful to get an understanding how the algorithm works. This often can help to either improve the input configuration or debug the program itself. Often this is resolved by adding debug statments.

For example:

\begin{lstlisting}
func Spexs(s *Setup) {
    for q, ok := s.In.Pop(); ok {
        trace("started extending %v", q)
        extended := s.Extend(q)
        trace("extension result %v", extended)
        for qx := range extended {
            if s.Extendable(qx) {
                trace(" > extendable %v" qx)
                s.In.Push(qx)
            }
            if s.Outputtable(qx) {
                trace(" > outputtable %v" qx)
                s.Out.Push(qx)
            }
        }
    }
}
\end{lstlisting}

Such statements make it harder to read the actual code, also it's hard to modify the statements for debugging or provide different ways of debugging.

We can use lexical closures to make it simpler:

\begin{lstlisting}
type Extender func(q Query) []Query

func AddDebuggingStatements(s *Setup) {
    fn := s.Extend
    s.Extend := func(q Query) []Query {
        trace("started extending %v", q)
        extended := fn(q)
        trace("extension result %v", extended)
        
        for qx := range extended {
            trace(" > %v", qx)
            trace(" > extendable %v", s.Extendable(qx))
            trace(" > outputtable %v", s.Outputtable(qx))
        }
        return extended
    }
}

func Spexs(s *Setup) {
    for q, ok := s.In.Pop(); ok {
        extended := s.Extend(q)
        for qx := range extended {
            if s.Extendable(qx) {
                s.In.Push(qx)
            }
            if s.Outputtable(qx) {
                s.Out.Push(qx)
            }
        }
    }
}

func run(){
    S := CreateSpexsSetup()
    AddDebuggingStatements(S)
    Spexs(S)
}
\end{lstlisting}

We have removed the debugging statements from the algorithm. We could define other such "debug statement injectors" that provide different levels of details. This method of course has a slight performance impact due to the additional indirection. This can be extended to provide user interaction and other features.