\chapter{SPEXS Generalization}
\label{c:generalization}

In this chapter we show how to make SPEXS algorithm more abstract by allowing flexibilty through function composition and finding minimal requirements for the data-structures.

\section{Algorithm}

The algorithm in a more conventional view is:

\begin{algorithm}[H]
	\caption{The spexs2 algorithm}
\begin{algorithmic}[1]
	\Require{$dataset$, $in$ and $out$ are pools, $extend$ is an extender function, $extend?$, $output?$ are filters}
	\Ensure{Patterns satisfying filters and $extender$ are in $out$ pool}
	\Statex
	\Function{spexs2}{dataset, in, out, extend, extend?, output?}
		\State prepare(in, dataset)
		\While{$q \gets $ in.pop()}
			\Let{extended}{extend($q$, dataset)}
			\For{ $qx \in $ extended }
				\If{ extend?($qx$) }
					\State in.push($qx$)
					\If{ output?($qx$) }
						\State out.push($qx$)
					\EndIf
				\EndIf
			\EndFor
		\EndWhile
	\EndFunction
\end{algorithmic}
\end{algorithm}

The algorithm starts by initializing the \emph{in} pool. The \emph{in} pool contains queries which we wish to examine further. In the simplest case this means that we create an empty pattern query and put it into the \emph{in} pool. We could also start the process with an already existing pattern.

As the next step, we pick a query from the \emph{in} pool for extending. Extending a query means generating all queries whose pattern size is larger by one. There can be several such queries.

If any of the queries should be further examined, as defined by the \emph{extendable} query filter, it will be put into the \emph{in} pool.

If the query is suitable for output, as defined by the \emph{outputtable} filter, it will be put into the \emph{out} pool. 

If we extend each pattern at each step by one we guarantee that we examine all the patterns that conform to our criteria as defined by \emph{extendable} filter.

\section{Pools}

Since pools act independently from the rest of the algorithm they are free to reorder, or store the queries on disk, or even discard the queries, if needed. If we wish to get 100 best results the, then the output pool may immediately discard the bad ones.

We can also use different types of structures as pools. For example, using a queue would make the query examining run breadth first, using a stack would make it run depth first. We can use priority queue to choose examine the best queries first in order to reach the interesting results faster as suggested in "Pattern Discovery from Biosequences"\cite{spexs}.

\section{Filtering}

Filtering allows us to reduce the number of queries we have to examine and enables selecting a subset of queries by some criteria.

The filters can make the decision, whether the query should be extended, based on any available information, for example, query pattern, number of occurrences, metadata in sequences, metadata in dataset or configuration data.

\begin{exmp}
Whether a sequence belongs to the input or the background dataset, can be considered metadata. We count the occurences of a pattern in each origin separately and then, if the ratio between origin dataset counts is larger than some number defined in the configuration, we can add it to output pool.
\end{exmp}

Although only one filter "function" has been specified in the algorithm the filter can be a composite of multiple filters.

\begin{exmp}
Pattern length greater than three and pattern matches at least 10 times in the dataset can be seen as a single filter that is composed of two filters.
\end{exmp}

\section{Extending}

The extending process is the core of the algorithm and there are several ways of doing it. The main criteria is that the query extending should guarantee that all possible queries get eventually enumerated.

The extender is analogous to an inductive step. Our base case is formulated by the \emph{prepare} step in the SPEXS2 algorithm and the induction steps are carried out by the extender.

\begin{exmp}
We start with an empty query and we know all its locations. If our extender generates all the queries where the patterns are larger by 1, then we are guaranteed to enumarate all the patterns.
\end{exmp}

\begin{exmp}
We can start with the empty query and all queries with patterns of length 1. Now if our extender generates queries where the patterns are larger by 2 we can also examine all of the queries.
\end{exmp}

The extender determines which patterns and pattern classes will be generated. We can modify and compose different extenders to get new patterns. Often more complex patterns can adversely affect algorithm runtime performance.

The general idea for extending is to find all the following patterns from all the previous query positions and then group the similar patterns into queries.

This process can be visualized with graphs. We make the sequence into a graph where the links between nodes are the sequence tokens. Each pattern then can walk the edges and match find the ending position for each pattern.

For example the sequence \R{ACGCCGATCGC} would look like:

\begin{figure}[H]
	\input{./diagrams/sequence2.tex}
\end{figure}

For simplicity we use nucleotides as our alphabet $\Sigma = \{ \R{A}, \R{C}, \R{G}, \R{T} \}$ in the following examples.

\subsection{Sequences}

The simplest case how the \emph{next} function behaves is when we are only looking for simple sequences. Let's consider the sequence \R{ACGCCGATCGC} and the pattern \R{CG}.

\begin{figure}[H]
	\input{./diagrams/sequence.tex}
\end{figure}

Initially we only have query \R{CG}. Then, by taking the \emph{next} token from the sequence we can build up queries \R{CGA} and \R{CGC}, including the match location set.

\subsection{Group tokens}

One common addition in a pattern language is matching a group of tokens. For example, we can use $\R{x} = \R{[AC]}$ to denote both tokens \R{A}, \R{C}. By adding a edge where either one transitions we can capture such groups in the extension process.

\begin{figure}[H]
	\input{./diagrams/groups.tex}
\end{figure}

There is a universal group \R{.} or \emph{wildcard} that matches any token in the alphabet.

\begin{exmp}
Pattern \R{T.} would match patterns \R{TA}, \R{TC}, \R{TG}, \R{TT}.
\end{exmp}

\subsection{Star}

Another possible extension is capturing a run of wildcards.

\begin{exmp}
A pattern \R{A.*T} would match \R{ACT}, \R{ATTC}, \R{ATTTC} and so on.
\end{exmp}

On the graph instead of \R{.*} we use only \R{*} symbol.

\begin{figure}[H]
	\input{./diagrams/star.tex}
\end{figure}

Constructing more complicated patterns increases the amount of queries that have to be enumerated. There are, of course, optimizations to avoid intermediary steps and repeated walking on the dataset. For example, we can skip the extension with only \R{.*} and instead extend with \R{.*Y}, where \R{Y} is a token from the alphabet. This means that we avoid a large query and, instead, have multiple smaller queries.

\begin{figure}[H]
	\input{./diagrams/star2.tex}
\end{figure}

We can limit the length of the run to speed up the process. Limiting the run length to 2 or 3 would look like:

\begin{figure}[H]
	\input{./diagrams/star3.tex}
\end{figure}

\subsection{Optimized group tokens}

Instead of immediately extending the group tokens, we can take the output of another extender and combine its results. If we have a group token $\gamma$ that contains $tokens(\gamma)$ then the match positions for such group is $$positions(p\gamma, D) = \bigcup_{t \in tokens(\gamma)} positions(pt, D) $$.

\begin{exmp}
A pattern \R{A[CTG]} is located in the document $D$ at positions $positions(\R{AC}, D) + positions(\R{AT}, D) + positions(\R{AG}, D)$.
\end{exmp}

\subsection{Other possible extensions}

By adding a edge from a node to itself and to the next node we can capture optional tokens.

\begin{exmp}
An optional token \R{Y?} means that the token \R{Y} can occur either zero or one time. For example \R{AT?} matches \R{A} and \R{AT}.
\end{exmp}

The graph for such token would look like:

\begin{figure}[H]
	\input{./diagrams/star4.tex}
\end{figure}

 Similarly, we can use the same technique that we used for the group tokens, to optimize the performance ($positions(pY, D) = positions(p) \cup positions(pY)$, where $Y$ is a token).

\subsection{Alternative extensions}

We mentioned that we can also extend by a different number of tokens at a time, as long as we guarantee that all patterns will be searched. For optimality we also do not want to iterate over the same pattern multiple times. As a simple example, the sequence \R{ACGCGA} could be iterated with the following setup:

\begin{figure}[H]
	\input{./diagrams/star5.tex}
\end{figure}

Since at the starting point we have all the patterns of length 0 and 1; then by adding patterns with length 2, we can be sure to enumerate all of them. Of course, the previous methods for group and star patterns extension need to be adjusted.

\section{Summary}

Although the extender was presented with graphs, practically it is much more reasonable to minimize the graph as simple sequence , as already mentioned in "Pattern Discovery from Biosequences"\cite{spexs}. The additional extension links shown in the graphs can either be precalculated or calculated at runtime.

We can also derive the minimal requirements for the dataset from the previous results. First, we need to get the initial empty query - which means we should somehow be able to get all the positions, from where a pattern could start. The other requirement is finding the next position and the token from a given position. Finding the next positions from a given position on sequence can be interpreted as a forward iterator.

The best way to visualize an extender was with graphs, suggesting that the \emph{spexs2} algorithm could be made to work on trees and then on graphs. Finding sequential patterns from a tree should be straightforward, since the generic algorithm is oblivious to the amount of following tokens any position can have. Graphs are more difficult, since we need to remove duplicates caused by extending the previous pattern graphs\cite{SubgraphIsomorphism}.

To use this generic version of the SPEXS algorithm we need to 1. choose our pool structures, 2. choose our filters, 3. choose our extender and initial queries and 4. dataset implementation.
