\chapter{Abstractification}

In this chapter we discuss the general structure of the new algorithm.

\section{Algorithm}

The algorithm in a more convetional view is:

\begin{verbatim}
func SPEXS(dataset, in, out, extender, extendable, outputtable, postprocess) {
	q := NewEmptyQuery(dataset)
	in.Put(q)
	while( !in.Empty() ) {
		q := in.Take()
		extended := extender(q)
		foreach qx in extended {
			if extendable(qx)
				in.Put(qx)
			if outputtable(qx)
				out.Put(qx)
		}
	}
}
\end{verbatim}

When the algorithm starts we create an empty pattern query and put 
into the in pool. The in pool contains querys whose patterns
should be further examined.

We pick a query from the in pool for extending. The extending means
generating all querys whose pattern is larger by one. There can be
several such querys.

If any of the querys should be further examined as defined by the
extendable filter, it will be put into the in pool.

If the query is fit for output we as defined by the outputtable filter,
it will be put into the out pool.

If we extend each pattern at each step by one we guarantee that we
examine the all patterns that conform to our criteria.

\section{Pools}

Pool is an abstract datatype for a collection of querys. The pool
allows querys to be put into it and taken from it, also we can
ask whether the pool is empty or not.

It has no guarantees on how the querys are stored internally and
in which order they are taken out.

In practice this means we can use any collection such as list, set,
queue as a pool. This gives us different performance characteristics.

\section{Filtering}

Filtering allows us to dramatically reduce the number of querys
we have to look at. It also allows to select only interesting patterns by
some criteria.

If we have interestingness measure we can create filter from it by
defining it's minimum or maximum value. One very usefule example 
would be a filter for limiting the pattern length.

By separating the extension and output filter, as opposed to SPEXS, 
we can still limit output without affecting the extension process.
For example if we wish to see only patterns of length 3 we cannot do
it with one filter. Since we need to extend patterns of length 0, 1 and 2.

\section{Extending}

The extending process is at the core of the algorithm. 
We shall look at how we can deal with different types.

The extending method is:

\begin{verbatim}

func extender(query) {
	// find all next positions
	nexts = new collection
	foreach pos in query.Matches {
		token, set of nexts = next(pos)
		nexts.add({token, set of nexts})
	}

	// group positions by the token
	matches = new map token => pos
	foreach x in nexts {
		matches[x.token].add(x.pos)
	}

	// make new querys from the matches
	result := new query collection
	foreach token, positions in matches {
		q := NewQuery( query.Pattern + token, positions )
		result.add(q)
	}

	return result
}

\end{verbatim}

\subsection{Sequences}

The simplest of the extensions are just sequences.

Let's consider a sequence ACGCCGATCGC and a pattern CG.

Diagram of the ACG.CCG.ATCG.C and query for that pattern.

Next positions step is finding ACG.[C]CG.[A]TCG.[C].

Grouping is [C] ==> CGC, [A] => CGA.

\subsection{DFAs}

Since we want to find more interesting patterns we can add more
information to the sequence DFA. Such as a star expression.

Same sequence with star paths.

\subsection{Groups}

Although we can add the group information to the DFA, it is more
performant to use the information gathered from the extension
of non-groups.

A[CG].Positions = AC.Positions union AG.Positions

\subsection{Other}

There maybe several other extensions to the regular expressions.

Questionable position:

AC?.Positions = A.Positions + AC.Positions