\chapter{Parallelization}

Here we discuss different ways how we can partition the algorithm to support parallelism.

\section{Process}

The main process of the algorithm as described by dataflow diagram.\cite{Kahn74,Lee95} Circles denote processes and unfinished rectangles denote data stores.

\begin{figure}[H]
	\input{./diagrams/process.tex}
\end{figure}

We can see that the different query extensions do not share a dependency, except the dataset. Since dataset itself is read-only for a given process, it means we can use multiple extender processes. The same applies for extendability and output filter.

\begin{figure}[H]
	\input{./diagrams/process2.tex}
\end{figure}

We can add more processes in a similar fashion without affecting the end result. Although this will introduce a source of indeterminism.

\section{Extending}

\emph{Extender} can be parallelized by using MapReduce\cite{MapReduce} concepts. We use here Clojure\cite{clojure} reducers library to show how this can be implemented.

\begin{algorithm}[H]
	\caption{Parallel extender}
\begin{lstlisting}[language=Lisp]
(require '[clojure.core.reducers :as r])

; fold-join based grouping function
(defn group-map-by [g f coll]
  (r/fold 
   (r/monoid (partial merge-with into) (constantly {}))
   (fn [ret x]
     (let [k (g x)]
       (assoc ret k (conj (get ret k []) (f x)))))
   coll))

(defn extend [dataset query]
   (let [ steps   (r/mapcat #(walk dataset %) (:positions query))
          grouped (group-map-by :token :position steps)]
        (r/map #(child-query q %) grouped))))
\end{lstlisting}
\end{algorithm}

This may not give much improvement on desktop CPUs, since we already can process multiple queries at the same time. This parallelization could be benefitial for highly parallel processors such as GPGPUs or FPGAs.

\section{Distributed processes}

Since the dataset and the process memory consumption can get quite it would also be benefitial to be able to partition the dataset between multiple machines.

The extension results for a given query stays inside the sequence which means we can partition by dividing sequences to separate datasets.

The whole dataset is required only for filtering, since even one of the simplest operations ("counting matches in dataset") requires full knowledge of all matches over the dataset. We can use partial results ($Z$) to reduce the communication overhead.

\begin{figure}[H]
	\input{./diagrams/process3.tex}
\end{figure}

For example to see whether some query is over some count limit we first count matches in the partial datasets, then send the partial results to a process that adds these results together. Depending on that result we can decide whether it needs further processing.
