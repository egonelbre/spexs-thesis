\chapter{Parallelization}

Here we describe parallel implementations of the parts of the algorithm.
A proof of concept for fully parallelized code can be seen in appendix A.

\section{Process}

The main process of the algorithm as described by dataflow.\cite{Kahn74,Lee95}

\begin{figure}[H]
	\input{./diagrams/process.tex}
\end{figure}

The easiest thing here to parallelize is the extender since it's interaction
can be seen as a separate unit.

\section{Adding Nodes}

If instead of in/out pool we had several the algorithm can still work, if we
have single take / put process to decide which actual pool to use.

We can use several extenders that work in parallel without problems since 
they do not need information about other querys nor input/output pools.

\section{Extending}

We still can also do the extending process in parallel:

\begin{verbatim}
func extender(query) {
	// find all next positions
	nexts = (map next query.matches)
	matches = (group nexts by token)
	result = (map newquery matches)
	other = (map #(union (matches %1)) groups)
	return result union other
}
\end{verbatim}

\section{Dataset partitioning}

If we look at where we need synchronization points if we partition 
the dataset. Whole parts of extension still apply for parts of dataset.

Synchronization is only needed for filtering. We don't need to know the 
whole query but just information about parts to make a decision whether to filter or not.

\section{Filtering}

This is the only place where we may need the whole information about the query.

Although many operations can be parallelized with map reduce.

\todo[inline]{example how to do counting}

\todo[inline]{example what cannot be done easily on sharded data}

